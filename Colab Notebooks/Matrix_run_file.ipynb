{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Matrix_run_file.ipynb","provenance":[{"file_id":"1TQZHVvw5A_VIiS0kH4RpbHmJdwFGy1Rj","timestamp":1576672623274}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"O4NygAiqvJAd","colab_type":"code","outputId":"37853243-d425-441a-af0f-a88b9999ef82","executionInfo":{"status":"ok","timestamp":1578673377715,"user_tz":-60,"elapsed":7476,"user":{"displayName":"Chao Yan","photoUrl":"","userId":"14937796898023384633"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["!pip install import-ipynb"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting import-ipynb\n","  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2975 sha256=c2740d05a59985765dc78479e7429ab628407e0d9a78176e1f154500c4be7165\n","  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TZBS1XpfL2DD","colab_type":"code","outputId":"bf149148-44dc-4055-9716-46c5aaccd020","executionInfo":{"status":"ok","timestamp":1578673405192,"user_tz":-60,"elapsed":34933,"user":{"displayName":"Chao Yan","photoUrl":"","userId":"14937796898023384633"}},"colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["import numpy as np\n","import tensorflow as tf\n","from sklearn.utils import shuffle\n","import matplotlib.pyplot as plt \n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers.merge import concatenate \n","from keras.layers import Flatten \n","from google.colab import drive\n","from keras.layers import Conv2D\n","from keras.optimizers import Adam\n","from keras.wrappers.scikit_learn import KerasClassifier,KerasRegressor\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/Colab Notebooks\"\n","import import_ipynb\n","from model_functions import *"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/Colab Notebooks\n","importing Jupyter notebook from model_functions.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0AFRuwex30Gt","colab_type":"code","colab":{}},"source":["\n","data = np.load('/content/drive/My Drive/ready_data_6C/matrix_input/10.npy')\n","label = np.load('/content/drive/My Drive/ready_data_6C/output/output.npy')\n","\n","print(data.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWhjlGAYc6TM","colab_type":"code","colab":{}},"source":["def compress():  # 将 30个hz频道 变成3个 频道\n","  L =[]\n","\n","  for i in range(96):\n","    a= 0\n","    b = 0\n","    c = 0\n","    New = []\n","    for j in range(0,2):\n","      a = a + data[i,j,:,:]\n","    a = a/2\n","    for j in range(2,4):\n","      b = b + data[i,j,:,:]\n","    b = b/2\n","    for j in range(4,6):\n","      c = c + data[i,j,:,:]\n","    c = c/2\n","    New.append(a)\n","    New.append(b)\n","    New.append(c)\n","    L.append(New)\n","  L = np.array(L)\n","\n","  return L\n","\n","A = compress()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9KVg2LssZi7","colab_type":"code","colab":{}},"source":["print(data.shape)\n","print(label.shape)\n","print(A.shape)\n","A = np.reshape(A, (96,116,116,3)) #变成 length,width, cns 标准 3d图像\n","print(A.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vDJd3yXmG2n","colab_type":"code","colab":{}},"source":["data, label = shuffle(data, label)\n","split = 72\n","train_data = data[:split]\n","train_label = label[:split]\n","test_data = data[split:]\n","test_label = label[split:]\n","train_data1 = A[:split]\n","test_data1 = A[split:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBWLW1Y73VoW","colab_type":"code","colab":{}},"source":["model1 = get_model4()\n","model2 = get_model5()\n","model3 = get_model6()\n","# model1.summary()\n","# model2.summary()\n","# model3.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mgd-TVKg0ocS","colab_type":"code","outputId":"4ffba486-d0e4-47cd-ada4-230c9e142122","executionInfo":{"status":"error","timestamp":1578673671877,"user_tz":-60,"elapsed":301506,"user":{"displayName":"Chao Yan","photoUrl":"","userId":"14937796898023384633"}},"colab":{"base_uri":"https://localhost:8080/","height":542}},"source":["history1 = model1.fit(train_data, train_label, epochs = 100, verbose=0)\n","history2 = model2.fit(train_data, train_label, epochs = 100, verbose=0)\n","history3 = model3.fit(train_data1, train_label, epochs = 10, verbose=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e3d79fbf4556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Matrix size-incompatible: In[0]: [1,147456], In[1]: [4608,256]\n\t [[{{node dense_14/MatMul}}]]\n\t [[loss_2/mul/_735]]\n  (1) Invalid argument: Matrix size-incompatible: In[0]: [1,147456], In[1]: [4608,256]\n\t [[{{node dense_14/MatMul}}]]\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"id":"7I828L781q6Y","colab_type":"code","colab":{}},"source":["mse1 = history1.history['loss']\n","mse2 = history2.history['loss']\n","mae1 = history1.history['mean_absolute_error']\n","mae2 = history2.history['mean_absolute_error']\n","# val_loss = history.history['val_loss']\n","# acc = history.history['acc']\n","# val_acc=history.history['val_acc']\n","epochs = range(1,len(mse1) +1)\n","plt.plot(epochs, mse1, 'c', label='mse1')\n","plt.plot(epochs, mse2, 'm', label='mse2')\n","plt.plot(epochs, mae1, 'c--', label='mae1')\n","plt.plot(epochs, mae2, 'm--', label='mae2')\n","plt.title('loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCiqhmnb0SrP","colab_type":"code","colab":{}},"source":["comparision1 = model1.predict(test_data)\n","comparision2 =model2.predict(test_data)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oorCp3DpyDY","colab_type":"code","colab":{}},"source":["x_data = range(24)\n","y_data_c1 = test_label[:,0]\n","y_data_c2 = test_label[:,1]\n","y_data_c3 = test_label[:,2]\n","y_predict1_c1 = comparision1[:,0]\n","y_predict1_c2 = comparision1[:,1]\n","y_predict1_c3 = comparision1[:,2]\n","y_predict2_c1 = comparision2[:,0]\n","y_predict2_c2 = comparision2[:,1]\n","y_predict2_c3 = comparision2[:,2]\n","\n","plt.plot(x_data, y_data_c1 , 'c', label='c1')\n","plt.plot(x_data, y_data_c2 , 'r', label='c2')\n","plt.plot(x_data, y_data_c3 , 'b', label='c3')\n","plt.plot(x_data, y_predict1_c1 , 'c--', label='predict1_c1')\n","plt.plot(x_data, y_predict1_c2 , 'r--', label='predict1_c2')\n","plt.plot(x_data, y_predict1_c3 , 'b--', label='predict1_c3')\n","plt.plot(x_data, y_predict2_c1 , 'c:', label='predict2_c1')\n","plt.plot(x_data, y_predict2_c2 , 'r:', label='predict2_c2')\n","plt.plot(x_data, y_predict2_c3 , 'b:', label='predict2_c3')\n","\n","plt.legend(loc=\"upper right\",fontsize = 'x-small')\n","\n","plt.title('loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.show() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4Nj-8wBb-YS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}